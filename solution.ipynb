{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a812c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from  sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ce079",
   "metadata": {},
   "source": [
    "Очистка кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13688586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_dataset_Самолет.csv', low_memory=False)\n",
    "test = pd.read_csv('test.csv', low_memory=False, sep = ';')\n",
    "train = pd.concat([train, test]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6752f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_cols = train.T.duplicated()\n",
    "drop_cols_0 = duplicates_cols[duplicates_cols].index\n",
    "train = train.drop(columns = drop_cols_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3091ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = train.columns[3:]\n",
    "# drop_cols = []\n",
    "# for i in tqdm(np.arange(len(cols))):\n",
    "#     all_cols = cols[max(0, i - 30): i].tolist() + cols[max(0, i + 1): i + 30].tolist()\n",
    "#     all_cols = sorted(set(all_cols) - set(drop_cols))\n",
    "#     tmp_df = train[all_cols].fillna(-999.4).values\n",
    "#     check = ((train[cols[i]].fillna(-999.4).values[:, None] != tmp_df) * (~train[cols[i]].isnull()).values[:, None]).sum(0)\n",
    "#     if check.min() == 0:\n",
    "#         drop_cols += [cols[i]]\n",
    "\n",
    "drop_cols_1 = ['col1', 'col5', 'col7', 'col25', 'col27', 'col29', 'col31', 'col33', 'col35', 'col45', 'col46', 'col47', 'col49', 'col50', 'col51', 'col54', 'col57', 'col58', 'col59', 'col62', 'col85', 'col86', 'col87', 'col89', 'col93', 'col94', 'col95', 'col101', 'col105', 'col106', 'col107', 'col109', 'col129', 'col130', 'col131', 'col137', 'col138', 'col139', 'col141', 'col142', 'col145', 'col146', 'col147', 'col153', 'col154', 'col155', 'col157', 'col158', 'col161', 'col162', 'col163', 'col169', 'col170', 'col171', 'col173', 'col181', 'col182', 'col183', 'col189', 'col190', 'col191', 'col201', 'col202', 'col203', 'col205', 'col209', 'col210', 'col211', 'col221', 'col222', 'col223', 'col233', 'col234', 'col237', 'col238', 'col239', 'col241', 'col457', 'col458', 'col459', 'col465', 'col466', 'col467', 'col513', 'col514', 'col515', 'col518', 'col521', 'col522', 'col523', 'col529', 'col530', 'col531', 'col537', 'col538', 'col539', 'col545', 'col546', 'col547', 'col553', 'col554', 'col555', 'col561', 'col562', 'col563', 'col569', 'col570', 'col571', 'col577', 'col578', 'col579', 'col585', 'col586', 'col587', 'col593', 'col594', 'col595', 'col601', 'col602', 'col603', 'col609', 'col610', 'col611', 'col773', 'col793', 'col794', 'col795', 'col801', 'col802', 'col803', 'col809', 'col810', 'col811', 'col817', 'col819', 'col905', 'col906', 'col966', 'col1005', 'col1017', 'col1029', 'col1030', 'col1031', 'col1032', 'col1033', 'col1034', 'col1035', 'col1037', 'col1038', 'col1039', 'col1041', 'col1045', 'col1046', 'col1047', 'col1053', 'col1054', 'col1055', 'col1061', 'col1062', 'col1063', 'col1070', 'col1071', 'col1073', 'col1077', 'col1081', 'col1082', 'col1089', 'col1090', 'col1094', 'col1117', 'col1118', 'col1119', 'col1121', 'col1122', 'col1123', 'col1125', 'col1126', 'col1133', 'col1134', 'col1137', 'col1145', 'col1165', 'col1166', 'col1167', 'col1174', 'col1175', 'col1177', 'col1179', 'col1181', 'col1197', 'col1230', 'col1234', 'col1237', 'col1250', 'col1273', 'col1274', 'col1277', 'col1278', 'col1281', 'col1285', 'col1317', 'col1321', 'col1327', 'col1341', 'col1347', 'col1357', 'col1359', 'col1373', 'col1377', 'col1402', 'col1425', 'col1437', 'col1445', 'col1446', 'col1447', 'col1449', 'col1450', 'col1451', 'col1647', 'col1649', 'col1650', 'col1651', 'col1661', 'col1664', 'col1667', 'col1682', 'col1685', 'col1688', 'col1691', 'col1694', 'col1706', 'col1707', 'col1708', 'col1709', 'col1710', 'col1711', 'col1712', 'col1713', 'col1714', 'col1715', 'col1716', 'col1717', 'col1718', 'col1719', 'col1720', 'col1730', 'col1733', 'col1736', 'col1739', 'col1742', 'col1743', 'col1744', 'col1754', 'col1757', 'col1760', 'col1763', 'col1766', 'col1778', 'col1779', 'col1780', 'col1781', 'col1782', 'col1783', 'col1784', 'col1785', 'col1786', 'col1787', 'col1788', 'col1789', 'col1790', 'col1791', 'col1792', 'col1802', 'col1803', 'col1804', 'col1805', 'col1806', 'col1807', 'col1808', 'col1809', 'col1810', 'col1811', 'col1812', 'col1813', 'col1814', 'col1815', 'col1816', 'col2047', 'col2065', 'col2066', 'col2067', 'col2137', 'col2196', 'col2197', 'col2242', 'col2463', 'col2464', 'col2465', 'col2466', 'col2467', 'col2468', 'col2469', 'col2471', 'col2472', 'col2473', 'col2474', 'col2475', 'col2477', 'col2543', 'col2562', 'col2585', 'col2586', 'col2587', 'col2591', 'col2594', 'col2595', 'col2596', 'col2597', 'col2598', 'col2599', 'col2600', 'col2606', 'col2609', 'col2610', 'col2611', 'col2615', 'col2618', 'col2619', 'col2620', 'col2621', 'col2622', 'col2623', 'col2624', 'col2630', 'col2631', 'col2632', 'col2633', 'col2634', 'col2635', 'col2639', 'col2658']\n",
    "train = train.drop(columns = drop_cols_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4303e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isnull_samples = (~train.isnull()).sum(0)\n",
    "drop_cols_2 = isnull_samples[isnull_samples < train.shape[0] * 0.02].index\n",
    "train = train.drop(columns = drop_cols_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b563962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arefi\\AppData\\Local\\Temp\\ipykernel_5436\\3192305251.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['cat_' + col] = train[col].astype('category').cat.codes.tolist()\n",
      "C:\\Users\\arefi\\AppData\\Local\\Temp\\ipykernel_5436\\3192305251.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['cat_' + col] = train[col].astype('category').cat.codes.tolist()\n",
      "C:\\Users\\arefi\\AppData\\Local\\Temp\\ipykernel_5436\\3192305251.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['cat_' + col] = train[col].astype('category').cat.codes.tolist()\n",
      "C:\\Users\\arefi\\AppData\\Local\\Temp\\ipykernel_5436\\3192305251.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['cat_' + col] = train[col].astype('category').cat.codes.tolist()\n",
      "C:\\Users\\arefi\\AppData\\Local\\Temp\\ipykernel_5436\\3192305251.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train['cat_' + col] = train[col].astype('category').cat.codes.tolist()\n"
     ]
    }
   ],
   "source": [
    "types = train.dtypes.astype('str')\n",
    "for col in types[types == 'object'].index[1:]:\n",
    "    train['cat_' + col] = train[col].astype('category').cat.codes.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a540255",
   "metadata": {},
   "source": [
    "Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0570e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10133 361\n",
      "10329 378\n",
      "10348 398\n",
      "9077 783\n",
      "9036 768\n",
      "9006 745\n"
     ]
    }
   ],
   "source": [
    "gkf = sklearn.model_selection.GroupKFold(3)\n",
    "split_list = []\n",
    "for date in ['2023-02-01', '2023-01-01']:\n",
    "    val_client = train[train.report_date >= date ]['client_id'].values\n",
    "    for _, tmp_index in gkf.split(val_client, val_client, val_client):\n",
    "        fold_val_client = val_client[tmp_index]\n",
    "        train_index =  train[(train.report_date >= '2021-07-01' ) & (train.report_date < date ) & (~train.client_id.isin(fold_val_client))].index\n",
    "        val_index =  train[(train.report_date <= '2023-02-01' ) & (train.report_date >= date ) & (train.client_id.isin(fold_val_client))].index\n",
    "        split_list += [(train_index, val_index)]\n",
    "        print(len(train_index), len(val_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f83e4b",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23cd7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_train(data, target, ltr, split_list, param, v_e = 0, n_e = 50, weight_col = []):\n",
    "    pred = pd.DataFrame()\n",
    "    pred_val = np.zeros(ltr)\n",
    "    fi = np.zeros(data.shape[1])\n",
    "    score = []\n",
    "    bst_list = []\n",
    "    pred_train = pd.DataFrame()\n",
    "    j = 0\n",
    "    full_tr = lgb.Dataset(np.array(data), np.array(target))\n",
    "\n",
    "    cv = lgb.cv(param, full_tr, 1000, folds = split_list,eval_train_metric = True,\n",
    "                callbacks = [lgb.early_stopping(400, verbose = None), \n",
    "                                                                      lgb.log_evaluation(50)] )\n",
    "    trees = np.argmax(cv['valid auc-mean']) + 1\n",
    "    print(trees, np.max(cv['valid auc-mean']))\n",
    "\n",
    "    for i , (train_index, test_index) in enumerate(split_list):\n",
    "\n",
    "        tr = lgb.Dataset(data.loc[train_index], target[train_index])\n",
    "        te = lgb.Dataset(data.loc[test_index], target[test_index], reference=tr)\n",
    "\n",
    "        bst = lgb.train(param, tr, num_boost_round=trees)\n",
    "\n",
    "        pred[str(i)] = bst.predict(np.array(data)[ltr:, :])\n",
    "        pred_val[test_index] = bst.predict(np.array(data)[test_index]) \n",
    "\n",
    "        score += [roc_auc_score(np.array(target)[test_index], pred_val[test_index])]\n",
    "        bst_list += [bst]\n",
    "        fi += np.array(bst.feature_importance(importance_type = 'gain'))\n",
    "        print(i+1, np.mean(score))\n",
    "        gc.collect()\n",
    "        del tr, te\n",
    "    pred_train[str(j)] = pred_val\n",
    "    return bst_list, pred_train, pred, score, fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d751b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occur(x):\n",
    "    x1 = pd.Series(np.arange(len(x)))\n",
    "    x1.index = x.index\n",
    "    x.update(np.arange(len(x)))\n",
    "    return x1\n",
    "\n",
    "train['time_occur'] = train.sort_values('report_date').groupby('client_id')['target'].apply(lambda x: occur(x))\n",
    "train['date_diff'] = pd.to_datetime(train['report_date']).dt.month + (pd.to_datetime(train['report_date']).dt.year - 2021) * 12\n",
    "train['month'] = pd.to_datetime(train['report_date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d612c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {\n",
    "'learning_rate': 0.1,\n",
    "'metric':'auc',\n",
    "'num_leaves': 16,\n",
    "'lambda_l1' : 10,\n",
    "'min_data_in_leaf' : 50,\n",
    "'max_bin':200,\n",
    "'extra_trees' : True,\n",
    "'verbosity' : -1, \n",
    "'objective': 'binary'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0c20942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's train auc: 0.851252 + 0.00136169\tcv_agg's valid auc: 0.927724 + 0.0365249\n",
      "[100]\tcv_agg's train auc: 0.86202 + 0.000821706\tcv_agg's valid auc: 0.933901 + 0.0335551\n",
      "[150]\tcv_agg's train auc: 0.867097 + 0.000776109\tcv_agg's valid auc: 0.933366 + 0.037549\n",
      "[200]\tcv_agg's train auc: 0.868628 + 0.000399804\tcv_agg's valid auc: 0.932406 + 0.0378805\n",
      "[250]\tcv_agg's train auc: 0.869807 + 0.000356673\tcv_agg's valid auc: 0.932174 + 0.0379359\n",
      "[300]\tcv_agg's train auc: 0.870633 + 0.000351653\tcv_agg's valid auc: 0.932187 + 0.0376106\n",
      "[350]\tcv_agg's train auc: 0.871169 + 0.000498134\tcv_agg's valid auc: 0.931737 + 0.0385046\n",
      "[400]\tcv_agg's train auc: 0.871517 + 0.000642036\tcv_agg's valid auc: 0.931267 + 0.0389312\n",
      "[450]\tcv_agg's train auc: 0.871831 + 0.00066697\tcv_agg's valid auc: 0.931329 + 0.0388786\n",
      "[500]\tcv_agg's train auc: 0.872032 + 0.000755737\tcv_agg's valid auc: 0.931275 + 0.0389167\n",
      "109 0.9354407024286729\n",
      "1 0.9663865546218489\n",
      "2 0.9676527367703839\n",
      "3 0.9555719099836747\n",
      "4 0.9528177744475165\n",
      "5 0.9346452367310647\n",
      "6 0.9351479644596838\n",
      "[50]\tcv_agg's train auc: 0.85574 + 0.00297742\tcv_agg's valid auc: 0.928555 + 0.0423192\n",
      "[100]\tcv_agg's train auc: 0.865913 + 0.00253411\tcv_agg's valid auc: 0.932809 + 0.0404335\n",
      "[150]\tcv_agg's train auc: 0.869181 + 0.00174906\tcv_agg's valid auc: 0.935313 + 0.0391408\n",
      "[200]\tcv_agg's train auc: 0.870697 + 0.00173228\tcv_agg's valid auc: 0.935849 + 0.0400156\n",
      "[250]\tcv_agg's train auc: 0.872128 + 0.00181851\tcv_agg's valid auc: 0.936418 + 0.0389868\n",
      "[300]\tcv_agg's train auc: 0.872773 + 0.00172799\tcv_agg's valid auc: 0.936105 + 0.0383976\n",
      "[350]\tcv_agg's train auc: 0.873181 + 0.00177021\tcv_agg's valid auc: 0.936325 + 0.0386707\n",
      "[400]\tcv_agg's train auc: 0.873811 + 0.00169569\tcv_agg's valid auc: 0.935446 + 0.0391608\n",
      "[450]\tcv_agg's train auc: 0.874571 + 0.00175886\tcv_agg's valid auc: 0.935948 + 0.039036\n",
      "[500]\tcv_agg's train auc: 0.874909 + 0.00185012\tcv_agg's valid auc: 0.93566 + 0.0394485\n",
      "[550]\tcv_agg's train auc: 0.875338 + 0.00180209\tcv_agg's valid auc: 0.935303 + 0.0399054\n",
      "[600]\tcv_agg's train auc: 0.875622 + 0.00176471\tcv_agg's valid auc: 0.935673 + 0.039516\n",
      "[650]\tcv_agg's train auc: 0.87586 + 0.00174101\tcv_agg's valid auc: 0.935939 + 0.039725\n",
      "253 0.9367469268739135\n",
      "1 0.9677871148459384\n",
      "2 0.9550084222878341\n",
      "3 0.9532321105850518\n",
      "4 0.9494502693924827\n",
      "5 0.9282644307175408\n",
      "6 0.9275277819004716\n",
      "[50]\tcv_agg's train auc: 0.857002 + 0.00158508\tcv_agg's valid auc: 0.917729 + 0.0395811\n",
      "[100]\tcv_agg's train auc: 0.865414 + 0.00111288\tcv_agg's valid auc: 0.923787 + 0.0409885\n",
      "[150]\tcv_agg's train auc: 0.868285 + 0.000874439\tcv_agg's valid auc: 0.924324 + 0.040245\n",
      "[200]\tcv_agg's train auc: 0.870017 + 0.000850317\tcv_agg's valid auc: 0.923562 + 0.042179\n",
      "[250]\tcv_agg's train auc: 0.871177 + 0.000844076\tcv_agg's valid auc: 0.923664 + 0.0418535\n",
      "[300]\tcv_agg's train auc: 0.872062 + 0.000796931\tcv_agg's valid auc: 0.923811 + 0.0422141\n",
      "[350]\tcv_agg's train auc: 0.87266 + 0.000960373\tcv_agg's valid auc: 0.923588 + 0.0423874\n",
      "[400]\tcv_agg's train auc: 0.873258 + 0.000925647\tcv_agg's valid auc: 0.923928 + 0.042165\n",
      "[450]\tcv_agg's train auc: 0.873713 + 0.000873737\tcv_agg's valid auc: 0.924458 + 0.0419336\n",
      "[500]\tcv_agg's train auc: 0.874044 + 0.000872708\tcv_agg's valid auc: 0.924802 + 0.0422033\n",
      "[550]\tcv_agg's train auc: 0.874372 + 0.000834155\tcv_agg's valid auc: 0.9249 + 0.0422801\n",
      "[600]\tcv_agg's train auc: 0.874676 + 0.000871257\tcv_agg's valid auc: 0.925442 + 0.0426384\n",
      "[650]\tcv_agg's train auc: 0.874956 + 0.000923296\tcv_agg's valid auc: 0.925391 + 0.0428433\n",
      "[700]\tcv_agg's train auc: 0.875118 + 0.0009892\tcv_agg's valid auc: 0.925206 + 0.0426726\n",
      "[750]\tcv_agg's train auc: 0.875341 + 0.000954806\tcv_agg's valid auc: 0.925649 + 0.0427457\n",
      "[800]\tcv_agg's train auc: 0.875503 + 0.000953258\tcv_agg's valid auc: 0.925598 + 0.0425654\n",
      "[850]\tcv_agg's train auc: 0.875624 + 0.00096567\tcv_agg's valid auc: 0.925585 + 0.0423629\n",
      "[900]\tcv_agg's train auc: 0.875867 + 0.000978436\tcv_agg's valid auc: 0.925496 + 0.0422873\n",
      "[950]\tcv_agg's train auc: 0.87597 + 0.000982799\tcv_agg's valid auc: 0.925463 + 0.0423271\n",
      "[1000]\tcv_agg's train auc: 0.876052 + 0.000999014\tcv_agg's valid auc: 0.925489 + 0.0422402\n",
      "749 0.9257483441557172\n",
      "1 0.9621848739495799\n",
      "2 0.9599775721099251\n",
      "3 0.9559038514920868\n",
      "4 0.953604282414181\n",
      "5 0.9345178681073986\n",
      "6 0.9335671956270984\n",
      "[50]\tcv_agg's train auc: 0.854899 + 0.00191558\tcv_agg's valid auc: 0.921397 + 0.0390853\n",
      "[100]\tcv_agg's train auc: 0.864575 + 0.00242704\tcv_agg's valid auc: 0.926991 + 0.0354686\n",
      "[150]\tcv_agg's train auc: 0.869309 + 0.00253703\tcv_agg's valid auc: 0.927434 + 0.03649\n",
      "[200]\tcv_agg's train auc: 0.871002 + 0.00226672\tcv_agg's valid auc: 0.927315 + 0.0374034\n",
      "[250]\tcv_agg's train auc: 0.871893 + 0.00224221\tcv_agg's valid auc: 0.927226 + 0.0387127\n",
      "[300]\tcv_agg's train auc: 0.872745 + 0.00224025\tcv_agg's valid auc: 0.926686 + 0.0380765\n",
      "[350]\tcv_agg's train auc: 0.873415 + 0.00220127\tcv_agg's valid auc: 0.927149 + 0.0378394\n",
      "[400]\tcv_agg's train auc: 0.873882 + 0.00211015\tcv_agg's valid auc: 0.927153 + 0.0377956\n",
      "[450]\tcv_agg's train auc: 0.874383 + 0.00208937\tcv_agg's valid auc: 0.927428 + 0.038654\n",
      "[500]\tcv_agg's train auc: 0.874778 + 0.00192958\tcv_agg's valid auc: 0.927115 + 0.038794\n",
      "117 0.9279622731357913\n",
      "1 0.9614845938375349\n",
      "2 0.9631747293511999\n",
      "3 0.9547233238409708\n",
      "4 0.9519893520421472\n",
      "5 0.9355316761815742\n",
      "6 0.9358597301513117\n",
      "[50]\tcv_agg's train auc: 0.852549 + 0.00264208\tcv_agg's valid auc: 0.927069 + 0.0345794\n",
      "[100]\tcv_agg's train auc: 0.863847 + 0.00208431\tcv_agg's valid auc: 0.932472 + 0.0419961\n",
      "[150]\tcv_agg's train auc: 0.868121 + 0.00193612\tcv_agg's valid auc: 0.931454 + 0.0420133\n",
      "[200]\tcv_agg's train auc: 0.87028 + 0.00191104\tcv_agg's valid auc: 0.931812 + 0.0415221\n",
      "[250]\tcv_agg's train auc: 0.871732 + 0.00176754\tcv_agg's valid auc: 0.933093 + 0.0411589\n",
      "[300]\tcv_agg's train auc: 0.872339 + 0.00162585\tcv_agg's valid auc: 0.932799 + 0.0413254\n",
      "[350]\tcv_agg's train auc: 0.872986 + 0.00145414\tcv_agg's valid auc: 0.932849 + 0.0412017\n",
      "[400]\tcv_agg's train auc: 0.87326 + 0.00142557\tcv_agg's valid auc: 0.932377 + 0.0412581\n",
      "[450]\tcv_agg's train auc: 0.873784 + 0.00152213\tcv_agg's valid auc: 0.932035 + 0.0414224\n",
      "[500]\tcv_agg's train auc: 0.874227 + 0.00140893\tcv_agg's valid auc: 0.931893 + 0.0415652\n",
      "105 0.9338877344734557\n",
      "1 0.9684873949579833\n",
      "2 0.9621153191006133\n",
      "3 0.9518802982038276\n",
      "4 0.9498186862546216\n",
      "5 0.932450121334669\n",
      "6 0.9336553747601449\n"
     ]
    }
   ],
   "source": [
    "bst_list_lgb = []\n",
    "for seed in [0, 1, 2, 3, 4]:\n",
    "    train_cols = ['col2663', 'time_occur', 'col2359', 'col1456', 'col1836', 'col2212', 'col1455', 'col2215', 'col2311', 'col2470', 'col1942', 'col2654', 'col2400', 'col2316', 'col1466', 'col1459', 'col1826', 'col1948'] \n",
    "    param_lgb['seed'] = seed\n",
    "    bst_list, pred_train, pred_test, score, fi = lgb_train(train[train_cols], train['target'], len(train), split_list, param_lgb, 10,)\n",
    "    bst_list_lgb += [bst_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8ab8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = train[train.report_date >= '2023-03-01'][train_cols]\n",
    "predict_lgb_test = []\n",
    "for bst_list in bst_list_lgb:\n",
    "    for bst in bst_list[3:]:\n",
    "        predict_lgb_test += [bst.predict(tmp_df)]\n",
    "lgb_predict = np.mean(predict_lgb_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0ce2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_train(data, target, ltr, split_list, param, v_e = 0, n_e = 50, trees = 700):\n",
    "    pred = pd.DataFrame()\n",
    "    pred_val = np.zeros(ltr)\n",
    "    fi = np.zeros(data.shape[1])\n",
    "    score = []\n",
    "    bst_list = []\n",
    "    pred_train = pd.DataFrame()\n",
    "    j = 0\n",
    "\n",
    "    tr = Pool(data.values, label= target.values)\n",
    "    cv = catboost.cv(tr, params_cat, iterations = 250,logging_level='Silent', folds = split_list)\n",
    "    trees = cv[cv['test-AUC-mean'] == cv['test-AUC-mean'].max()]['iterations'].iloc[0]\n",
    "    print(trees, cv['test-AUC-mean'].max())\n",
    "    # trees = 2\n",
    "    for i , (train_index, test_index) in enumerate(split_list):\n",
    "        tr = Pool(data.loc[train_index].values, label= target.values[train_index])\n",
    "        bst = catboost.train(tr, param, num_boost_round=trees , verbose = 0)\n",
    "\n",
    "        pred[str(i)] = bst.predict(np.array(data.loc[ltr:]), prediction_type = 'Probability')[:, 1]\n",
    "        pred_val[test_index] = bst.predict(np.array(data.loc[test_index]), prediction_type = 'Probability')[:, 1] \n",
    "\n",
    "        score += [roc_auc_score(np.array(target)[test_index], pred_val[test_index])]\n",
    "        bst_list += [bst]\n",
    "        fi += np.array(bst.get_feature_importance())\n",
    "        print(i+1, np.mean(score))\n",
    "#         print()\n",
    "        gc.collect()\n",
    "        del tr\n",
    "        # , te\n",
    "    pred_train[str(j)] = pred_val\n",
    "    return bst_list, pred_train, pred, score, fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69d47dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cols = ['col2663', 'time_occur', 'col2558', 'col1499', 'col1475', 'col1848', 'col1845', 'col1457', 'col2307', 'col2656', 'col1500', 'col1839', 'col1850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d32a9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cat = {\n",
    "    'loss_function' :'Logloss', \n",
    "    'max_depth' : 6, \n",
    "    'eval_metric' :'AUC', \n",
    "    'learning_rate' : 0.1, \n",
    "#     'grow_policy' : 'Depthwise',\n",
    "    'grow_policy' : 'SymmetricTree',\n",
    "    'l2_leaf_reg' : 30, \n",
    "    'random_strength' : 20,\n",
    "    'random_state' : 148 ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d5365d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 0.9331854700428844\n",
      "1 0.9719887955182073\n",
      "2 0.9586295328942388\n",
      "3 0.9468855005619711\n",
      "4 0.9465909415787507\n",
      "5 0.9288231315504991\n",
      "6 0.9290976537969305\n",
      "118 0.936558652117316\n",
      "1 0.9607843137254902\n",
      "2 0.9567435082140965\n",
      "3 0.9524657576128165\n",
      "4 0.9501809876920266\n",
      "5 0.9343972220018258\n",
      "6 0.9362071764904248\n",
      "120 0.9422511982196075\n",
      "1 0.9761904761904763\n",
      "2 0.9597168597168597\n",
      "3 0.9545548295548295\n",
      "4 0.9540899817883\n",
      "5 0.938857430368793\n",
      "6 0.939695079067293\n",
      "105 0.9360300576544244\n",
      "1 0.9712885154061625\n",
      "2 0.956928041486865\n",
      "3 0.9494904891963717\n",
      "4 0.9496485841450133\n",
      "5 0.9376701102606486\n",
      "6 0.938570976391523\n",
      "105 0.9318971110950717\n",
      "1 0.9712885154061626\n",
      "2 0.9609820955409192\n",
      "3 0.9490949013007838\n",
      "4 0.9485167680505379\n",
      "5 0.9359360276264516\n",
      "6 0.9356782130672919\n"
     ]
    }
   ],
   "source": [
    "bst_list_cat = []\n",
    "for seed in [0, 10, 50, 100, 1000]:\n",
    "    params_cat['random_state'] = seed\n",
    "    bst_list, pred_train, pred_test, score, fi = cat_train(train[best_cols], train['target'], len(train), split_list, params_cat, 10)\n",
    "    bst_list_cat += [bst_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b747467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bst_list in bst_list_cat:\n",
    "#     for (_, val), bst in zip(split_list, bst_list[3:]):\n",
    "#         pred = bst.predict(train.loc[val, best_cols])\n",
    "#         np.mean(train.loc[val[np.argsort(-pred)], 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1d4fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_predict = []\n",
    "tmp_df = train[train.report_date >= '2023-03-01'][best_cols]\n",
    "for bst_list in bst_list_cat:\n",
    "    for bst in bst_list[3:]:\n",
    "        cat_predict += [ bst.predict(tmp_df, prediction_type = 'Probability')[:, 1] ]\n",
    "cat_predict = np.mean(cat_predict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97f49e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bf38258",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = cat_predict + lgb_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "279d3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_1.csv', index = None, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90d5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
